# -*- coding: utf-8 -*-
"""Suicide_and_Depression_Detector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tITKlgOR4cuSZzMuyugEJEm7WV0dPoxR

Run the line below to connect your google drive.
"""

from google.colab import drive
import os
import pandas as pd

# connect notebook to google drive for dataset loading and preparation
drive.mount('/content/drive/', force_remount=True)
folder_path = '/content/drive/MyDrive/CS_4650_Project/'

"""Lets combine all 3 csv files and create a new file 'combined_data.csv'."""

from sklearn.model_selection import train_test_split

# combine 3 csv files
depression_df = pd.read_csv(os.path.join(folder_path, 'Depression.csv'), encoding='latin-1')
neutral_df = pd.read_csv(os.path.join(folder_path, 'Neutral.csv'), encoding='latin-1')
suicidal_df = pd.read_csv(os.path.join(folder_path, 'Suicadal_tendencies_data.csv'), encoding='latin-1')

combined_df = pd.concat([depression_df, neutral_df, suicidal_df], ignore_index=True)

output_path = os.path.join(folder_path, 'combined_data.csv')
combined_df.to_csv(output_path, index=False)

# replace empty labels with 0.0 and shuffle data
combined_df = pd.read_csv(os.path.join(folder_path, 'combined_data.csv'), encoding='latin-1')
combined_df['Label'].fillna(0.0, inplace=True)
combined_df = combined_df.dropna(subset=['TEXT'])
combined_df = combined_df.sample(frac=1, random_state=42).reset_index(drop=True)
combined_df = combined_df.drop(columns=['Unnamed: 2'])
combined_df.to_csv(os.path.join(folder_path, 'combined_data.csv'), index=False)

from google.colab import drive
drive.mount('/content/drive')

"""Split data into training and testing sets."""

# split into 80/20 splits for Training/Testing
train_df, test_df = train_test_split(combined_df, test_size=0.2, random_state=42)

train_labels = train_df['Label']
train_text = train_df['TEXT']
test_labels = test_df['Label']
test_text = test_df['TEXT']

"""Now lets implement Logistic Regression with BOW as a vectorization method."""

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import matplotlib.pyplot as plt

# BOW vectorization using CountVectorizer from sklearn
vectorizer = CountVectorizer(max_features=10000)
X_train_bow = vectorizer.fit_transform(train_text)
X_test_bow = vectorizer.transform(test_text)

# implementation of logistic regression
log_reg = LogisticRegression(max_iter=1000, random_state=42)
log_reg.fit(X_train_bow, train_labels)

log_reg_train_preds = log_reg.predict(X_train_bow)
log_reg_test_preds = log_reg.predict(X_test_bow)

# outputting logistic regression metrics - train and test accuracy, classfication report, and confusion matrix
print("Logistic Regression Training Accuracy:", accuracy_score(train_labels, log_reg_train_preds))
print("Logistic Regression Testing Accuracy:", accuracy_score(test_labels, log_reg_test_preds))
print("\nLogistic Regression Classification Report:\n", classification_report(test_labels, log_reg_test_preds))

conf_matrix = confusion_matrix(test_labels, log_reg_test_preds)
class_labels = ['Neutral (0.0)', 'Depression (1.0)', 'Suicide (2.0)']
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix - Logistic Regression")
plt.show()

"""Now lets implement Naive Bayes and SVM models using the same BOW vectorization."""

from sklearn.naive_bayes import MultinomialNB
from sklearn.svm import SVC

# implementing multinomial (multiclass) naive bayes from sklearn
nb_model = MultinomialNB()
nb_model.fit(X_train_bow, train_labels)
nb_train_preds = nb_model.predict(X_train_bow)
nb_test_preds = nb_model.predict(X_test_bow)

# output naive bayes metrics - test and training accuracy, classification report, and confusion matrix
print("Naive Bayes Training Accuracy:", accuracy_score(train_labels, nb_train_preds))
print("Naive Bayes Testing Accuracy:", accuracy_score(test_labels, nb_test_preds))
print("\nNaive Bayes Classification Report:\n", classification_report(test_labels, nb_test_preds))

conf_matrix = confusion_matrix(test_labels, nb_test_preds)
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix - Naive Bayes")
plt.show()

# implementing SVM using SVC from sklearn
svm_model = SVC(kernel='linear', C=1.0, random_state=42)  # Linear kernel for text classification
svm_model.fit(X_train_bow, train_labels)
svm_train_preds = svm_model.predict(X_train_bow)
svm_test_preds = svm_model.predict(X_test_bow)

# output SVM metrics - test and training accuracy, classification report, and confusion matrix
print("SVM Training Accuracy:", accuracy_score(train_labels, svm_train_preds))
print("SVM Testing Accuracy:", accuracy_score(test_labels, svm_test_preds))
print("\nSVM Classification Report:\n", classification_report(test_labels, svm_test_preds))

# conf_matrix = confusion_matrix(test_labels, svm_test_preds)
# disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)
# disp.plot(cmap="Blues", values_format="d")
# plt.title("Confusion Matrix - SVM")
# plt.show()

"""Lets output 5 random sentences that the Naive Bayes model misclassified and predicted wrong."""

import random
import numpy as np

# output 5 random misclassificaitons where Naive Bayes (baseline model) predicted wrong.

# find misclassified indices from predicted
misclassified_indices = []
for idx, (true_label, predicted_label) in enumerate(zip(test_labels, nb_test_preds)):
  if true_label != predicted_label:
    misclassified_indices.append(idx)

# print out true label, predicted label, and input text from misclassified indices
selected_indices = random.sample(misclassified_indices, min(5, len(misclassified_indices)))
for idx in selected_indices:
  if idx < len(test_labels):
    correct_label = test_labels.iloc[idx]
    if correct_label == 0.0:
      final_correct_label = "Neutral"
    elif correct_label == 1.0:
      final_correct_label = "Depression"
    elif correct_label == 2.0:
      final_correct_label = "Suicidal"
    guessed_label = nb_test_preds[idx]

    if guessed_label == 0.0:
      final_guessed_label = "Neutral"
    elif guessed_label == 1.0:
      final_guessed_label = "Depression"
    elif guessed_label == 2.0:
      final_guessed_label = "Suicidal"
    print(f"True Label: {final_correct_label}")
    print(f"Predicted Label: {final_guessed_label}")
    print(f"Input Text: {test_text.iloc[idx]}")
    print("-" * 50)
  else:
    print(f"Index {idx} is out of range for test_labels.")

"""Lets implement a LSTM model."""

import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout
from tensorflow.keras.optimizers import Adam


# use Tokenizer to tokenize text, preparation for LSTM model
max_words = 10000
max_sequence_length = 100
tokenizer = Tokenizer(num_words=max_words)
tokenizer.fit_on_texts(train_text)

# convert text to sequences and pad sequeunces
X_train_seq = tokenizer.texts_to_sequences(train_text)
X_test_seq = tokenizer.texts_to_sequences(test_text)
X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)
X_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length)

# initializing the LSTM model
model = Sequential()
model.add(Embedding(input_dim=10000, output_dim=128))
model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))
model.add(Dense(3, activation='softmax'))

# train and evaluate model
model.compile(loss='sparse_categorical_crossentropy', optimizer=Adam(learning_rate=0.0001), metrics=['accuracy'])
model.fit(X_train_pad, train_labels, epochs=5, batch_size=64, validation_data=(X_test_pad, test_labels))
train_preds = model.predict(X_train_pad)
test_preds = model.predict(X_test_pad)

# convert predictions to labels by finding max
train_preds_labels = np.argmax(train_preds, axis=1)
test_preds_labels = np.argmax(test_preds, axis=1)

# output LSTM metrics - training and test accuracy, classification report, and confusion matrix
print("Training Accuracy:", accuracy_score(train_labels, train_preds_labels))
print("Testing Accuracy:", accuracy_score(test_labels, test_preds_labels))
print("\nClassification Report:\n", classification_report(test_labels, test_preds_labels))

conf_matrix = confusion_matrix(test_labels, test_preds_labels)
class_labels = ['Neutral (0.0)', 'Depression (1.0)', 'Suicide (2.0)']
disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=class_labels)
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix - LSTM")
plt.show()

"""We will now be implementing a Bidirectional Encoder Representations from Transformers."""

# installing transformers, torch, and sklearn packages if don't already have (most likely have)
!pip install transformers
!pip install torch
!pip install sklearn

import torch
from torch.utils.data import DataLoader, Dataset
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_recall_fscore_support
import pandas as pd

# implement BERT model

# using BERTTokenizer from transformers package tokenize train_text and test_text
tokenizer = BertTokenizer.from_pretrained("bert-base-uncased")
train_encodings = tokenizer(list(train_text), truncation=True, padding=True, max_length=128)
test_encodings = tokenizer(list(test_text), truncation=True, padding=True, max_length=128)

# TextDataset class for preparing the dataset
class TextDataset(Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels.iloc[idx], dtype=torch.long)
        return item

    def __len__(self):
        return len(self.labels)

train_dataset = TextDataset(train_encodings, train_labels)
test_dataset = TextDataset(test_encodings, test_labels)

# initialize BERT model
model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=3)

# metrics that will be outputted for BERT model
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

# arguments for training - epochs = 3, weight decay = 0.05
training_args = TrainingArguments(
    output_dir='./results',
    num_train_epochs=3,
    per_device_train_batch_size=8,
    per_device_eval_batch_size=16,
    warmup_steps=500,
    weight_decay=0.05,
    logging_dir='./logs',
    logging_steps=10,
    evaluation_strategy="epoch",
    report_to=[]
)

# train and evaluate the BERT model
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics
)

trainer.train()
eval_results = trainer.evaluate()
print(eval_results)

# print confusion matrix
predictions, true_labels, _ = trainer.predict(test_dataset)
predicted_labels = predictions.argmax(axis=-1)
cm = confusion_matrix(true_labels, predicted_labels)
disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=["Neutral", "Depression", "Suicide"])
disp.plot(cmap="Blues", values_format="d")
plt.title("Confusion Matrix - BERT Model")
plt.show()

"""Utilizng the trained BERT model, we can test how accurate it is given custom sentences from user inputting prompting."""

# predict the sentiment of a given input sentence based on the BERT model
def predict_sentiment(model, tokenizer, input_sentence):
  # encode
  encoding = tokenizer(input_sentence, return_tensors='pt', truncation=True, padding=True)
  device = next(model.parameters()).device

  input_ids = encoding["input_ids"].to(device)
  attention_mask = encoding["attention_mask"].to(device)

  predictions = {1.0: "Depressed", 0.0: "Neutral", 2.0 : "Suicidal"}

  model.eval()
  with torch.no_grad():
    # input it to model
    outputs = model(input_ids, attention_mask=attention_mask)
    logits = outputs.logits
    predicted_class = torch.argmax(logits, dim=1).item()

  model.train()

  return predictions[predicted_class]

# user inputted prompting using the BERT model - calling predict_sentiment() method
def test_BERT_custom_input():
  while True:
    user_input = input("Enter a sentence to predict its sentiment (or 'exit' to quit): ")
    if user_input.lower() == 'q':
      break
    prediction = predict_sentiment(model, tokenizer, user_input)
    print(f"Predicted Sentiment: {prediction}\n")


test_BERT_custom_input()

"""Now using Gemini 1.5 API, we can use it to compare what an LLM and BERT model would predict (Neutral, Depression, Suicide) given a user inputted prompt. Because Gemini is a better trained model with greater context recognition, if there is a difference in prediction between our BERT model and Gemini, the Gemini prediction will be taken and used to retrain the BERT model (in a separate csv file). This is a form of reinforcement learning, gradually with more user inputs and data improving our BERT model."""

# install google generative ai package if don't have (most likely don't)
!pip install -q -U google-generativeai

import google.generativeai as genai
from google.colab import userdata

# get own personal API_KEY and configure it
API_KEY = userdata.get('gemini')
genai.configure(api_key=API_KEY)

# new file used to retrain model
feedback_file = os.path.join(folder_path, 'bert_feedback_file.csv')

# initializes new csv file, if already exists read it
def initialize_log_file():
    try:
        return pd.read_csv(feedback_file)
    except FileNotFoundError:
        return pd.DataFrame(columns=["Label", "TEXT"])

# clears the csv file - mostly used for testing user inputs
def clear_csv_file():
    empty_df = pd.DataFrame(columns=["Label", "TEXT"])
    empty_df.to_csv(feedback_file, index=False)

# returns the gemini prediction (Neutral, Depression, Suicide) based off custom prompt
def get_gemini_classification(user_input):
    model = genai.GenerativeModel("gemini-1.5-flash")
    prompt = f"""
    Based on the following user input: "{user_input}", classify the user's emotional state as one of the following:
    'Suicidal', 'Depressed', or 'Neutral'. Only return one of these words.
    """
    response = model.generate_content(prompt)
    return response.text.strip()

# adds the new entry into the csv file (50 times) and saves it
def log_discrepancy(user_input, correct_output, df):
    new_entry = pd.DataFrame({"Label": [correct_output], "TEXT": [user_input]})
    for i in range(50):
      df = pd.concat([df, new_entry], ignore_index=True)
    df.to_csv(feedback_file, index=False)
    return df

# prepares the new csv file (feedback file) for retraining
def prepare_feedback_data(feedback_file):
    feedback_df = pd.read_csv(feedback_file)
    encodings = tokenizer(list(feedback_df['TEXT']), truncation=True, padding=True, max_length=128)
    labels = pd.Series(feedback_df['Label'].values)
    return encodings, labels

# retrains bert once threshold is reached
def retrain_bert(log_df, model, tokenizer):

    # encode and use TextDataset from before
    encodings, labels = prepare_feedback_data(feedback_file)
    train_dataset = TextDataset(encodings, labels)

    # training arguments - experimented with 3 and 6 epochs
    training_args = TrainingArguments(
        output_dir='./results',
        num_train_epochs=6,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=16,
        warmup_steps=500,
        weight_decay=0.05,
        logging_dir='./logs',
        logging_steps=10,
        evaluation_strategy="epoch",
        report_to=[]
    )

    # train model
    trainer = Trainer(
      model=model,
      args=training_args,
      train_dataset=train_dataset,
      eval_dataset=test_dataset,
    )

    trainer.train()
    model.save_pretrained('./fine_tuned_model')

# function where tests BERT and Gemini model on user prompt input
def test_BERT_custom_input():

    # initialize new csv file
    log_df = initialize_log_file()
    last_retrained_length = len(log_df)

    # prompts user
    while True:
        user_input = input("Enter a sentence to predict its sentiment (or 'q' to quit): ")
        if user_input.lower() == 'q':
            break

        # BERT model prediction
        bert_prediction = predict_sentiment(model, tokenizer, user_input)
        print(f"Predicted Sentiment: {bert_prediction}\n")

        # Gemini model prediction
        gemini_prediction = get_gemini_classification(user_input)
        print(f"Gemini Prediction: {gemini_prediction}")

        # if predictions from both models is same, don't add to csv file and no need to retrain using the prompt
        # if predictions from both models are different, add to csv file to later be used for retraining
        if bert_prediction == gemini_prediction:
            final_output = bert_prediction
        else:
            final_output = gemini_prediction
            log_final_output = None
            if final_output == "Depressed":
              log_final_output = 1.0
            elif final_output == "Suicidal":
              log_final_output = 2.0
            elif final_output == "Neutral":
              log_final_output = 0.0
            # add to csv file
            log_df = log_discrepancy(user_input, log_final_output, log_df)
        print(f"Final Output: {final_output}\n")

        # Only retrain when user has inputted 100 user prompts, as more data will train the model better
        current_length = len(log_df)
        if current_length != 0 and current_length % 5000 == 0 and current_length != last_retrained_length:
            retrain_bert(log_df, model, tokenizer)
            last_retrained_length = current_length

# Uncomment if you want to clear the csv file
# clear_csv_file()

test_BERT_custom_input()

"""Now we retry the BERT model on the original dataset test data again to see if there is an improvement in accuracy based off of user prompts and user reinforced learning."""

# initialize BERT model
model = BertForSequenceClassification.from_pretrained("bert-base-uncased", num_labels=3)  # Adjust 'num_labels' if needed

# metrics used for BERT model
def compute_metrics(pred):
    labels = pred.label_ids
    preds = pred.predictions.argmax(-1)
    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='weighted')
    acc = accuracy_score(labels, preds)
    return {
        'accuracy': acc,
        'f1': f1,
        'precision': precision,
        'recall': recall
    }

# arguments for training - epochs = 3, weight decay = 0.05
training_args = TrainingArguments(
    output_dir='./results',          # Output directory
    num_train_epochs=3,              # Number of training epochs
    per_device_train_batch_size=8,   # Batch size for training
    per_device_eval_batch_size=16,   # Batch size for evaluation
    warmup_steps=500,                # Number of warmup steps for learning rate scheduler
    weight_decay=0.05,               # Strength of weight decay
    logging_dir='./logs',            # Directory for storing logs
    logging_steps=10,
    evaluation_strategy="epoch",
    report_to=[]                     #prevents API from being called
)

# train and evaluate the model
trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=train_dataset,
    eval_dataset=test_dataset,
    compute_metrics=compute_metrics
)
trainer.train()
eval_results = trainer.evaluate()
print(eval_results)

"""Lets plot a bar graph chart displaying the accuracy of Naive Bayes, LSTM, BERT with Reinforcement Learning, BERT without Reinforcement Learning"""

import matplotlib.pyplot as plt

# plot different models and their accuracies for bar graph chart
models = ['Naive Bayes', 'LSTM', 'BERT (No RL)', 'BERT (With RL)']
accuracies = [0.8437853107344633, 0.8782485875706215, 0.9514124293785311, 0.9550847457627119]

plt.figure(figsize=(10, 6))
plt.bar(models, accuracies, color=['blue', 'green', 'orange', 'red'], width=0.4)
plt.title('Model Accuracy Comparison', fontsize=14)
plt.xlabel('Models', fontsize=12)
plt.ylabel('Accuracy', fontsize=12)

for i, v in enumerate(accuracies):
    plt.text(i, v + 0.005, f"{v:.4f}", ha='center', va='bottom', fontsize=14)

plt.tight_layout()
plt.show()

# Colab2PDF v1.0.2 by Drengskapur (github.com/drengskapur/colab2pdf) (License: GPL-3.0-or-later)
# @title {display-mode:"form"}
# @markdown ⬇️ Download PDF
def colab2pdf():
    ENABLE=True # @param {type:"boolean"}
    if ENABLE:
        import os, datetime, json, locale, pathlib, urllib, requests, werkzeug, nbformat, google, yaml, warnings
        locale.setlocale(locale.LC_ALL, 'en_US.UTF-8')
        NAME = pathlib.Path(werkzeug.utils.secure_filename(urllib.parse.unquote(requests.get(f"http://{os.environ['COLAB_JUPYTER_IP']}:{os.environ['KMP_TARGET_PORT']}/api/sessions").json()[0]["name"])))
        TEMP = pathlib.Path("/content/pdfs") / f"{datetime.datetime.now().strftime('%Y%m%d_%H%M%S')}_{NAME.stem}"; TEMP.mkdir(parents=True, exist_ok=True)
        NB = [cell for cell in nbformat.reads(json.dumps(google.colab._message.blocking_request("get_ipynb", timeout_sec=30)["ipynb"]), as_version=4).cells if "--Colab2PDF" not in cell.source]
        warnings.filterwarnings('ignore', category=nbformat.validator.MissingIDFieldWarning)
        with (TEMP / f"{NAME.stem}.ipynb").open("w", encoding="utf-8") as nb_copy: nbformat.write(nbformat.v4.new_notebook(cells=NB or [nbformat.v4.new_code_cell("#")]), nb_copy)
        if not pathlib.Path("/usr/local/bin/quarto").exists():
            !wget -q "https://quarto.org/download/latest/quarto-linux-amd64.deb" -P {TEMP} && dpkg -i {TEMP}/quarto-linux-amd64.deb > /dev/null && quarto install tinytex --update-path --quiet
        with (TEMP / "config.yml").open("w", encoding="utf-8") as file: yaml.dump({'include-in-header': [{"text": r"\usepackage{fvextra}\DefineVerbatimEnvironment{Highlighting}{Verbatim}{breaksymbolleft={},showspaces=false,showtabs=false,breaklines,breakanywhere,commandchars=\\\{\}}"}],'include-before-body': [{"text": r"\DefineVerbatimEnvironment{verbatim}{Verbatim}{breaksymbolleft={},showspaces=false,showtabs=false,breaklines}"}]}, file)
        !quarto render {TEMP}/{NAME.stem}.ipynb --metadata-file={TEMP}/config.yml --to pdf -M latex-auto-install -M margin-top=1in -M margin-bottom=1in -M margin-left=1in -M margin-right=1in --quiet
        google.colab.files.download(str(TEMP / f"{NAME.stem}.pdf"))
colab2pdf()